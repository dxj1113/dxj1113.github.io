---
title: 凸优化简论
date: 2017-07-17 14:10:26
tags: [机器学习,算法,凸优化]
categories: 技术
---
# 概论
## 说明

最近在学习机器学习方面的算法知识，发现凸优化是机器学习中重要的数学基础，特地买了本书做学习，这里记录下一些学习心得，先搭个框架，内容会逐步展开，后续会陆续更新。、

主要参考资料[《凸优化》](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787/ref=sr_1_1?ie=UTF8&qid=1500272157&sr=8-1&keywords=Stephen%20Boyd)(Stephen Boyd等著，王书宁等译)[1]这本书。
(各种公式用mathjax语法写的，写的崩溃了.....)
 <!-- more -->

## 什么是凸优化

不严格的说，凸优化就是在标准优化问题的范畴内，要求目标函数和约束函数是凸函数的一类优化问题。
[维基百科的定义](https://zh.wikipedia.org/wiki/%E5%87%B8%E5%84%AA%E5%8C%96)：
**凸优化**，或叫做凸最优化，凸最小化，是数学最优化的一个子领域，研究定义于凸集中的凸函数最小化的问题。凸优化在某种意义上说较一般情形的数学最优化问题要简单，譬如在凸优化中局部最优值必定是全局最优值。凸函数的凸性使得凸分析中的有力工具在最优化问题中得以应用，如次导数等。
凸优化应用于很多学科领域，诸如自动控制系统，信号处理，通讯和网络，电子电路设计，数据分析和建模，统计学(最优化设计），以及金融。在近来运算能力提高和最优化理论发展的背景下，一般的凸优化已经接近简单的线性规划一样直捷易行。许多最优化问题都可以转化成凸优化（凸最小化）问题，例如求凹函数f最大值的问题就等同于求凸函数 -f最小值的问题。

## 重要性

> “凸优化在数学规划领域具有非常重要的地位。”
> 
> “一旦将一个实际问题表述为凸优化问题，大体上意味着相应问题已经得到彻底解决，这是非凸的优化问题所不具有的性质。”
> 
> ——《<凸优化>译者序》

凸优化之所以如此重要，是因为：

1. 其应用非常广泛，机器学习中很多优化问题都要通过凸优化来求解；

2. 在非凸优化中，凸优化同样起到重要的作用，很多非凸优化问题，可以转化为凸优化问题来解决；

3. 如上引用所述，凸优化问题可以看作是具有成熟求解方法的问题，而其他优化问题则未必。

## 凸优化知识体系

* **凸集**，定义目标函数和约束函数的定义域。

* **凸函数**，定义优化相关函数的凸性限制。

* **凸优化**，中心内容的标准描述。

* **凸优化问题求解**，核心内容。相关算法，梯度下降法、牛顿法、内点法等。

* **对偶问题**，将一般优化问题转化为凸优化问题的有效手段，求解凸优化问题的有效方法。


## 标准优化问题
$$min\qquad f_0(x)$$
$$s.t.\qquad f_i(x)\le0,\qquad i=1,\cdots m$$
$$\qquad \qquad h_i(x)\le0,\qquad i=1,\cdots p$$                
$$(1)$$
表示在所有满足$$f_i(x)\le0,\qquad i=1,\cdots m$$及$$h_i(x)=0,\qquad i=1,\cdots p$$的$x$中找出使$$f_0(x)$$最小的x.
这里,$$x \in \mathbf R^n$$,函数$$f_0:\mathbf R^n \to \mathbf R$$称为目标函数。
不等式$$ f_i(x)\le0$$称为不等式约束，相应的$$f_i:\mathbf R^n\to \mathbf R,i=1,2,\cdots m$$称为不等式约束函数，方程组$$h_i(x)=0$$称为等式约束，相应的$$h_i:\mathbf R^n\to \mathbf R,i=1,2\cdots p$$称为等式约束。
如果没有约束，即$$m=p=0$$,称问题1为无约束问题。
对目标和所有约束函数有定义的点的集合
$$\mathcal{D}=\bigcap\limits_{i=0}\limits^{m} domf_i \frown \bigcap\limits_{j=1}\limits^{p} domh_j$$
称为优化问题1的定义域


## 凸优化问题
$$min\qquad f_0(x)$$
$$s.t.\qquad f_i(x)\le0,\qquad i=1,\cdots m$$
$$a_1^T X=b_i,\qquad i=1,\cdots p$$                
$$(2)$$
上述优化问题中，$$f_i(x),i=0,1,2\cdots m$$是凸函数，此类问题被称为凸优化问题。
对比优化问题，也就是说，目标函数和不等式约束同为凸函数，等式约束是仿射函数的优化问题属于凸优化问题。


# 凸集

## 定义

### 直线上的点
$\forall x,y\in \mathbf R^n 且 x\neq y$,那么，

$$Z=\theta X+(1-\theta)Y,\theta\in \mathbf R \qquad \qquad \qquad (1)$$
是一条穿越X和Y的直线

A,$\theta$=0时，Z=Y
B,$\theta$=1时，Z=X
C,$0\lt \theta \lt 1$时，Z是X和Y之间线段上的点
D,$\theta \lt 0或\theta\gt 1$时，线段上的点Z是X和Y线段之外的点

### 定义
集合C中任意两点之间的线C中，则称集合C为凸集，也即满足$\forall x,y\in \mathbf C,0\lt \theta \lt 1有\theta x+(1-\theta)y\in \mathbf C$的集合称为凸集。

## 典型的凸集

* 线段，射线，直线

* 超平面，半空间

* 仿射集

* 欧几里得球，范数球，椭球等

* 凸锥，范数锥等

## 其它相关知识
### 保凸运算

交集、仿射函数、线性分式函数及透视函数

### 超平面分离定理

两个不相交的凸集，存在一个超平面将其分离。


# 凸函数
## 定义
函数$f:\mathbf R^n \to \mathbf R 定义域domf$是凸集，并且对于$\forall x,y\in domf和\forall \theta 0\lt \theta \lt 1有$

$$f(\theta x+(1-\theta)y)\le \theta f(x)+(1-\theta)f(y) \qquad \qquad \qquad \qquad (1)$$
则称函数$f$是凸的




## 性质
### 一阶条件
可微函数$f$是凸函数的充分必要条件是
A,定义域$domf$是凸集。
B,对于$\forall x,y\in domf有f(y)\ge f(x)+\forall f(x)^T(y-x)$


### 二阶条件
函数f的二阶偏导称为函数f的Hessian矩阵。
对于函数定义域domf内任意一点，其Hessian矩阵存在，则函数f是凸函数的重要条件是：其Hessian矩阵是半正定阵，也即，对于所有的$x\in domf有\forall^2f(x)\succ=0$
对于R上的函数，可以简化为$f(x)\ge 0$(f上面有两小撇，这个公式暂时没找到)


### 下水平集
函数f的下水平集$C_a=\{ x\in domf\mid f(x)\le a\}$是其定义域的子集。凸函数的下水平集是凸集。



### 上境图
函数$f:\mathbf R^n \to \mathbf R$的上境图$epi f=((x,t)\mid x \in domf,f(x)\le t))$,它是空间$\mathbf R+{n+1}$上的子集。一个函数是凸函数，当且仅当其上境图是凸集。


## 典型凸函数

1. 线性函数和仿射函数

2. 指数函数

3. 负熵

4. 范数

## 保凸运算

非负加权求和、复合仿射映射、逐点最大和逐点上确界、复合等。

## Jensen不等式
Jensen当年提出的不等式相当简单，f是凸函数，则
$$f(\frac{x+y}2) \le \frac{f(x)+f(y)}{2}$$


Jensen不等式，又叫詹森不等式，以丹麦数学家约翰·詹森(Johan Jensen)命名。

5.1、常规形式


5.2、概率形式


5.3、推广

Jensen不等式用途非常广泛。凸性和Jensen不等式可以构成不等式理论的基础，很多著名的不等式都可以通过Jensen不等式应用于合适的凸函数得到[1]。

例如，算数-几何平均不等式可以由负对数函数利用Jensen不等式得到。


A、参考

[1]、《凸优化》，Stephen Boyd等著，王书宁等译

